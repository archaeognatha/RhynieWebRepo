using CSV,DelimitedFiles,DataFrames,Random,Distributions,StatsPlots,LinearAlgebra,PoissonRandom,Graphs,Colors,FilePathsBase
println(pwd())
cd(@__DIR__)

dir_path = "SLNs/Messel/" # user-defined path 
analysis_name = "Messel10s"

# store the filenames of the matrix files from the specified directory 
matrix_files = sort(filter(f -> occursin(r"matrix_.*\.csv", f), readdir(dir_path; join=true)))
info_files = sort(filter(f -> occursin(r"speciesinfo_.*\.csv", f), readdir(dir_path; join=true)))

n_SLNs = length(matrix_files)

#---------------------------------------------------#
#   Robust Longest Chain Calculation (Handles Loops)
#---------------------------------------------------#

# 1. Define a recursive function to find depth
#    'current_node': The species we are looking at
#    'visited': A list of species already in this specific food chain

function get_longest_path(node_id, matrix, visited, start_time, time_limit)
    
    prey_list = findall(matrix[node_id, :] .== 1)
    
    # Base case: No prey, return just myself as a path
    if isempty(prey_list)
        return [node_id]
    end
    
    # Store the longest path found among all prey
    longest_path_below = Int[] 
    
    for prey in prey_list
        # Time check
        if (time() - start_time) > time_limit
            break 
        end

        if !(prey in visited)
            push!(visited, prey)
            
            # RECURSIVE CALL: Get the path from the prey
            path_below = get_longest_path(prey, matrix, visited, start_time, time_limit)
            
            # If this new path is longer than the best one we've seen, keep it
            if length(path_below) > length(longest_path_below)
                longest_path_below = path_below
            end
            
            delete!(visited, prey)
        end
    end
    
    # Return [Me, Prey, Prey's Prey...]
    return vcat(node_id, longest_path_below)
end

# Create dataframe for storing results
max_chain_df = DataFrame(SLN_ID = String[], max_chain_len = Int64[])

# Loop over all webs in the folder 
for index in 1:n_SLNs
    ### File input ###
    ## Read the species info and adjacency matrix files.
    sp_P = CSV.read(info_files[index], DataFrame)
    sp_A_df = CSV.read(matrix_files[index], DataFrame; header = false)
    sp_A = Matrix(sp_A_df)

    # FORCE CONVERT guild column to strings
    sp_P.guild = string.(sp_P.guild)
    
    # pull the name/number of the network from the matrix filename
    webname = match(r"matrix_(.*)\.csv", matrix_files[index])
    SLN_ID = webname !== nothing ? webname.captures[1] : missing

     no_species = size(sp_A)[1]


    #  Run the following for every species in this web
    #    (We re-initialize the 'visited' set for each species)

    max_len_global = 0
    best_path_global = Int[]

    println("Scanning species in $SLN_ID...")
    for i in 1:size(sp_A, 1)
        t0 = time()
        # Call the new function
        path = get_longest_path(i, sp_A, Set([i]), t0, 10)
        
        if length(path) > max_len_global
            max_len_global = length(path)
            best_path_global = path
            # Print progress so you see it happening
            println("  Found new max length: $(length(path)) starting at node $i")
        end
    end

    # --- PRINT THE ACTUAL NAMES ---
    println("\n=== THE LONGEST CHAIN FOR $analysis_name===")
    # Map the IDs back to names using your species info dataframe (sp_P)
    # Assuming sp_P has a column 'species_name' or similar, change as needed:
    chain_names = sp_P.sp_name[best_path_global] 

    for (idx, name) in enumerate(chain_names)
        println("$idx. $name")
    end

    # Calculate the metric
    max_chain_len = length(chain_names)

    push!(max_chain_df, (SLN_ID, max_chain_len))
end

# save SLN_stats_out as a csv
CSV.write(joinpath(dir_path, "MAXCHAINLENS_$analysis_name.csv"), max_chain_df)

println("$analysis_name average max chain length: ", mean(max_chain_df.max_chain_len))

