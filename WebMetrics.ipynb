{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2378b349",
   "metadata": {},
   "source": [
    "## Rhynie Chert SLN Metrics Calculator ##\n",
    "### Adapted from \"Analytical approaches to networks, trophic structure, and ancient food webs\" NAPC 2024 food web workshop\n",
    "\n",
    "\n",
    "### Rhynie network ###\n",
    "The following script takes two types of files describing Species Level Networks (SLNs) as input. The first is a list of taxa and associated information like trophic guild assignment, habitat (terrestrial vs. aquatic), etc. The second file is the species-level adjacency matrix, which is a binary $\\vert U\\vert\\times \\vert U\\vert$ matrix, where $\\vert U\\vert$ is the total number of species in the network, $U$. The entries in this matrix are 0 or 1. If species $G_i$ preys on species $G_j$, then the $ij^{th}$ entry is 1, and zero otherwise.\n",
    "\n",
    "### Code note ###\n",
    "Note that much of the code and software written by Peter Roopnarine for working with metanetworks, constructing species-level food webs, calculating their metrics and simulating their dynamics, have been written using the Julia programming language. You must have Julia installed on your system to operate the code, and the Jupyter notebook environment installed for Julia. Helpful links are:\n",
    "\n",
    "https://julialang.org/\n",
    "\n",
    "https://jupyter.org/\n",
    "\n",
    "The following blocks of code are therefore all Julia. The code is licensed with the GNU General Protection License which, if you are not familiar with (but you should be!), allows users to freely reuse, modify and redistribute the original code. But please familiarize yourself with the obligations and restrictions of the license."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743f98cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load necessary Julia libraries\n",
    "# these must be installed via the Julia repl or terminal environment. Do so with the following commands\n",
    "# using Pkg\n",
    "# Pkg.add(\"CSV\")\n",
    "using CSV,DelimitedFiles,DataFrames,Random,Distributions,StatsPlots,LinearAlgebra,PoissonRandom,Graphs,Colors,FilePathsBase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862ce77e",
   "metadata": {},
   "source": [
    "# Directory choice #\n",
    "Input which directory the SLN or SLNs you want to analyze are stored in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704b907b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the path from your working directory to the folder the SLN files are in\n",
    "## note that the matrix files should be named \"matrix_XXX.csv\" and the info files should be named \"speciesinfo_XXX.csv\"\n",
    "dir_path = \"SLNs/DigelSoil_trophospecies/\"\n",
    "# add a label for this analysis that will become the output table's filename\n",
    "analysis_name = \"soilTS_firstgo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "08b9e405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"SLNs/DigelSoil//SLNmetricssoil_firstgo.csv\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create an empty dataframe to populate with metric values for each web\n",
    "SLN_stats_out = DataFrame(SLN_ID = String[], Detritus = Int64[], S = Float64[], interactions = Float64[], L_D = Float64[], C = Float64[], \n",
    "    Basal = Float64[], Top = Float64[], Herbiv = Float64[], Carniv = Float64[],\n",
    "    meanInDegree = Float64[], stdInDegree = Float64[], \n",
    "    mean_longest_chain = Float64[], mean_NTP = Float64[], max_NTP = Float64[], mean_NTP_norm = Float64[], \n",
    "    TrOmniv = Float64[], q_inCoherence = Float64[], \n",
    "    mean_path_len = Float64[], std_path_len = Float64[], \n",
    "    Modularity = Float64[]\n",
    ")\n",
    "\n",
    "# store the filenames of the matrix files from the specified directory \n",
    "matrix_files = filter(f -> startswith(f, \"$(dir_path)matrix\") && isfile(f),\n",
    "    readdir(dir_path; join=true)\n",
    ")\n",
    "\n",
    "# store the filenames of the info files from the specified directory \n",
    "info_files = filter(f -> startswith(f, \"$(dir_path)species\") && isfile(f),\n",
    "    readdir(dir_path; join=true)\n",
    ")\n",
    "\n",
    "n_SLNs = length(matrix_files)\n",
    "\n",
    "#### the main loop begins below ####\n",
    "for index in 1:n_SLNs\n",
    "    ### File input ###\n",
    "    ## Read the species info and adjacency matrix files.\n",
    "    sp_P = CSV.read(info_files[index], DataFrame)\n",
    "    sp_A_df = CSV.read(matrix_files[index], DataFrame; header = false)\n",
    "    sp_A = Matrix(sp_A_df)\n",
    "    \n",
    "    # pull the name/number of the network from the matrix filename\n",
    "    webname = match(r\"matrix_(.*)\\.csv\", matrix_files[index])\n",
    "    SLN_ID = webname !== nothing ? webname.captures[1] : missing\n",
    "     \n",
    "    #------------------------------------#\n",
    "    ### Basic stats ###\n",
    "\n",
    "    ## no. of interactions \n",
    "    interactions = sum(sp_A)\n",
    "    no_species = size(sp_A)[1]\n",
    "    ## link density\n",
    "    L_D = interactions/no_species\n",
    "    ## connectance\n",
    "    C = interactions/(no_species*(no_species-1))\n",
    "\n",
    "    #------------------------------------#\n",
    "    ### Check if no_preds and no_prey columns are missing/empty and fill in if so\n",
    "\n",
    "    # Make sure sp_no_prey and sp_no_preds columns are mutable and allow missing type\n",
    "    for colname in [:sp_no_prey, :sp_no_preds]\n",
    "        if !( colname in names(sp_P) )\n",
    "            sp_P[!, colname] = Vector{Union{Missing, Int}}(missing, nrow(sp_P))\n",
    "        elseif !(eltype(sp_P[!, colname]) <: Union{Missing, Int})\n",
    "            T = nonmissingtype(eltype(sp_P[!, colname]))\n",
    "            sp_P[!, colname] = Vector{Union{Missing, T}}(sp_P[!, colname])\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Fill in missing predator/prey counts\n",
    "    for i in 1:no_species\n",
    "        if ismissing(sp_P.sp_no_prey[i])\n",
    "            sp_P.sp_no_prey[i] = sum(sp_A[i, :])  # Row = outgoing links (prey)\n",
    "        end\n",
    "        if ismissing(sp_P.sp_no_preds[i])\n",
    "            sp_P.sp_no_preds[i] = sum(sp_A[:, i])  # Col = incoming links (predators)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    #------------------------------------#\n",
    "    ### Trophic Composition ###\n",
    "\n",
    "    ## Basal: fraction of total species (minus detritus) that eat only basal species\n",
    "\n",
    "    # Identify basal species (no incoming links)\n",
    "    is_basal = [sum(sp_A[i, j] for j in 1:no_species) == 0 for i in 1:no_species]\n",
    "    # Identify how many of the taxa are detritus and reports how many detrital nodes are reported in the web\n",
    "    detritalnodes = findall(occursin.(\"detritus\", coalesce.(sp_P.guild, \"\")))\n",
    "    Detritus = length(detritalnodes)\n",
    "\n",
    "    Basal = (sum(is_basal)-length(detritalnodes))/(no_species-length(detritalnodes))\n",
    "\n",
    "    ## Top: fraction of total species (minus detritus) have no predators\n",
    "    is_top = [sum(sp_A'[i, j] for j in 1:no_species) == 0 for i in 1:no_species]\n",
    "\n",
    "    Top = sum(is_top)/no_species\n",
    "\n",
    "    ## Herbivores + Carnivores: fraction of consumer species that eat only basal species and only non-basal species\n",
    "\n",
    "    herbivores = 0\n",
    "    carnivores = 0\n",
    "    consumers = 0\n",
    "\n",
    "    for i in 1:no_species\n",
    "        prey = findall(sp_A[i, :] .== 1)\n",
    "        if !isempty(prey)\n",
    "            consumers += 1\n",
    "            if all(is_basal[j] for j in prey)\n",
    "                herbivores += 1\n",
    "            end\n",
    "            if all(!is_basal[j] for j in prey)\n",
    "                carnivores += 1\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    Herbiv = herbivores/consumers\n",
    "    Carniv = carnivores/consumers\n",
    "    #------------------------------------#\n",
    "    ## Mean and st. dev. in-degree (generality), mean # of prey species\n",
    "\n",
    "    meanInDegree = sum(sp_P.sp_no_prey)/consumers\n",
    "    stdInDegree = std(sp_P.sp_no_prey[sp_P.sp_no_prey .!= 0])\n",
    "\n",
    "    #------------------------------------#\n",
    "    ### Chain length/NTP analyses ###\n",
    "\n",
    "    # store number of guilds for later use\n",
    "    # no_guilds = maximum(sp_P.guild_no)\n",
    "    # add columns to the species dataframe to store the longest chain and ntp\n",
    "    sp_P[!, :sp_ntp] = fill(0.0, nrow(sp_P))\n",
    "    sp_P[!, :sp_long_chain] = fill(0.0, nrow(sp_P))\n",
    "\n",
    "    #initialize pathways matrix\n",
    "        paths = Array{Int64}(undef,no_species,no_species)\n",
    "        paths = deepcopy(sp_A)\n",
    "        #longest possible pathway\n",
    "        P_max = no_species - 1 # was number of guilds but generalizing for networks not from a guild metaweb\n",
    "        #set initial longest path for each species\n",
    "        for i = 1:no_species\n",
    "            if sp_P[i,:sp_no_prey] > 0\n",
    "                sp_P[i,:sp_long_chain] = 1\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        #calculate pathways by raising binary adjacency matrix to pathway lengths\n",
    "        for i = 1:P_max\n",
    "            A2 = sp_A^i\n",
    "            for j = 1:no_species\n",
    "                for k = 1:no_species\n",
    "                    #if path now exists between species\n",
    "                    if paths[j,k]==0 && A2[j,k]>0\n",
    "                        #update the pathways matrix\n",
    "                        paths[j,k] = i\n",
    "                    end\n",
    "                end\n",
    "                #list as longest chain if one exists\n",
    "                if sum(paths[j,:]) != 0\n",
    "                    sp_P[j,:sp_long_chain] = maximum(paths[j,:])\n",
    "                end\n",
    "            end       \n",
    "            if sum(A2)==0\n",
    "                break\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        #calculate ntps\n",
    "        #build vector of primary producers\n",
    "        prods = Int64[]\n",
    "        for i = 1:no_species\n",
    "            if sp_P[i,:sp_no_prey] == 0\n",
    "                push!(prods,i)\n",
    "            end\n",
    "        end\n",
    "        #calculate path length of prey to producers\n",
    "        for i = 1:no_species\n",
    "            #if producer\n",
    "            if sp_P[i,:sp_no_prey]==0\n",
    "                sp_P[i,:sp_ntp] = 1\n",
    "            elseif sp_P[i,:sp_no_prey]>0\n",
    "                #else if consumer\n",
    "                #list prey\n",
    "                its_prey = Int64[]\n",
    "                path_length = 0\n",
    "                no_paths = 0\n",
    "                for j = 1:no_species\n",
    "                    #if species is producer prey of i\n",
    "                    if paths[i,j] == 1 && sp_P[j,:sp_no_prey] == 0\n",
    "                        no_paths+=1\n",
    "                    end\n",
    "                    #if species is consumer prey of i\n",
    "                    if paths[i,j] == 1 && sp_P[j,:sp_no_prey] > 0\n",
    "                        #record path lengths to producers\n",
    "                        for k = 1:no_species\n",
    "                            if paths[j,k]!=0 && sp_P[k,:sp_no_prey]==0\n",
    "                                path_length = path_length + paths[j,k]\n",
    "                                no_paths+=1\n",
    "                            end\n",
    "                        end\n",
    "                    end \n",
    "                end\n",
    "                #if herbivore\n",
    "                if path_length==0\n",
    "                    sp_P[i,:sp_ntp] = 2.0\n",
    "                elseif path_length > 0\n",
    "                    #if not herbivore\n",
    "                    sp_P[i,:sp_ntp] = 2.0 + (Float64(path_length)/Float64(no_paths))\n",
    "                    #println(species[i,6])\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "\n",
    "\n",
    "    ## mean longest chain length\n",
    "    mean_longest_chain = mean(sp_P.sp_long_chain)\n",
    "\n",
    "    ## mean net trophic position (ntp)\n",
    "    mean_NTP = mean(sp_P.sp_ntp)\n",
    "\n",
    "    ## max and normalized mean ntp (divide by max value of ntp)\n",
    "    max_NTP = maximum(sp_P.sp_ntp)\n",
    "    mean_NTP_norm = mean_NTP / max_NTP\n",
    "\n",
    "    ## Trophic Omnivory: fraction of consumer species that eat across trophic levels\n",
    "    num_integers = count(x -> isfinite(x) && x % 1 == 0, sp_P.sp_ntp)\n",
    "    trophic_omnivores = no_species - num_integers\n",
    "    TrOmniv = trophic_omnivores/consumers\n",
    "\n",
    "    #------------------------------------#\n",
    "    ## Trophic Coherence ###\n",
    "\n",
    "    ## incoherence (q) is a metric from Johnson et al. 2014 and is related to TrophOmniv\n",
    "    ## it is the standard deviation of differences between ntps of predator and prey across for all links in the web\n",
    "\n",
    "    # make a list of all edges (trophic links) in the SLN\n",
    "    graph = DiGraph(sp_A)\n",
    "    links = collect(edges(graph))\n",
    "\n",
    "    # create an empty vector to store ntp differences for all edges \n",
    "    troph_distances = Float64[]\n",
    "\n",
    "    # Loop through all edges and calculate ntp differences\n",
    "    # note that the direction of source and destination seems backwards from an energy POV-->in graphs the standard direction is from the predator to the prey\n",
    "    for e in edges(graph)\n",
    "        i = src(e) # consumer sp ID\n",
    "        j = dst(e) # resource sp ID\n",
    "        ntp_i = sp_P[i, :sp_ntp]\n",
    "        ntp_j = sp_P[j, :sp_ntp]\n",
    "        push!(troph_distances, ntp_i - ntp_j)\n",
    "    end\n",
    "\n",
    "    # compute standard deviation\n",
    "    q_inCoherence = std(troph_distances)\n",
    "\n",
    "    #------------------------------------#\n",
    "    ### Pairwise path lengths ####\n",
    "\n",
    "    # Compute all-pairs shortest paths\n",
    "    all_paths = floyd_warshall_shortest_paths(SimpleDiGraph(sp_A))\n",
    "\n",
    "    # Extract all finite path lengths\n",
    "    lengths = Float64[]\n",
    "    for i in 1:no_species\n",
    "        for j in 1:no_species\n",
    "            d = all_paths.dists[i, j]\n",
    "            if i != j && (d) < 100000\n",
    "                push!(lengths, d)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    mean_path_len = mean(lengths)\n",
    "    std_path_len = std(lengths)\n",
    "\n",
    "    #------------------------------------#\n",
    "    ### Modularity ###\n",
    "\n",
    "\n",
    "    \n",
    "    #------------------------------------#\n",
    "    #### Metrics Output ####\n",
    "\n",
    "    # save updated speciesinfo with path length and ntp info\n",
    "    CSV.write(info_files[index], sp_P)\n",
    "\n",
    "    # push metrics to SLN_stats_out\n",
    "    push!(SLN_stats_out, (SLN_ID, Detritus, no_species, interactions, L_D, C, \n",
    "        Basal, Top, Herbiv, Carniv,\n",
    "        meanInDegree, stdInDegree, mean_longest_chain, mean_NTP, max_NTP, mean_NTP_norm,\n",
    "        TrOmniv, q_inCoherence, mean_path_len, std_path_len, 0    \n",
    "    ))  # Order must match column order\n",
    "\n",
    "end\n",
    "\n",
    "# save SLN_stats_out as a csv\n",
    "CSV.write(\"$(dir_path)/SLNmetrics$(analysis_name).csv\", SLN_stats_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294da552",
   "metadata": {},
   "source": [
    "The SLN matrix is a sparse matrix (i.e. most of the elements are zero), as are all realistic and real world food web matrices, so there isn't much point in printing it. But we can visualize the resulting graph (network)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a457ba",
   "metadata": {},
   "source": [
    "Given this matrix, we can now compute several network metrics, namely:\n",
    "1. The total number of interactions, $L$.\n",
    "2. Link density, or the average number of interactions per species. \n",
    "$$L_D = \\frac{L}{S}$$\n",
    "3. Connectance, the ratio of the number of interactions to the number of interactions possible given $S$.\n",
    "$$C = \\frac{L}{S(S-1)}$$\n",
    "4. Trophic composition: fraction of species with different trophic modes:\n",
    "    - Basal\n",
    "    - Top\n",
    "    - Herbiv: fraction of consumer species that eat only basal species\n",
    "    - Carniv: fraction of consumer species that eat other consumers\n",
    "5. Network trophic level, or ntp , is a measure of the average number of steps or links between a taxon and primary producers (Roopnarine and Dineen, 2018). By definition, primary producers will be of ntp 1, primary consumers (e.g. herbivores) will be of ntp 2, and secondary consumers will be of greater ntp. It is calculated as the average of the shortest distances between a taxon's prey and a primary producer.\n",
    "$$\\textrm{ntp}_i = 2 + \\frac{1}{k_i}\\sum_{j=1}^S a_{ij}d_{j}$$\n",
    "where $k_i$ is the number of prey of taxon $i$, $a_{ij}$ is the binary indicator of whether taxon $i$ preys on taxon $j$, and $d_j$ is the shortest distance, or number of links, between taxon $j$ and a primary producer.\n",
    "6. Trophic Omnivory: fraction of consumer species that eat across trophic levels -- calculated by looking for non-integer ntp\n",
    "6. Mean in-degree for consumers (generality)\n",
    "7. Mean shortest path length\n",
    "8. Max chain length \n",
    "9. PathSD: standard dev. of path lengths\n",
    "10. Trophic coherence [Johnson et al 2014]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1166bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Omnivores: fraction of consumer species that eat both basal species + consumers\n",
    "\n",
    "# Step 1: Identify basal species (no incoming links)\n",
    "is_basal = [sum(sp_A[i, j] for j in 1:nvertices) == 0 for i in 1:nvertices]\n",
    "\n",
    "# Step 2: For each consumer, check if they eat both basal and consumer prey\n",
    "omnivores = 0\n",
    "consumers = 0\n",
    "\n",
    "for i in 1:nvertices\n",
    "    prey = findall(sp_A[i, :] .== 1)\n",
    "\n",
    "    if !isempty(prey)\n",
    "        consumers += 1\n",
    "        has_basal = any(is_basal[j] for j in prey)\n",
    "        has_consumer = any(!is_basal[j] for j in prey)\n",
    "\n",
    "        if has_basal && has_consumer\n",
    "            omnivores += 1\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "Omniv = omnivores/consumers\n",
    "SLN_stats_out.Omniv = [Omniv] #replace this with a push! when you make it a loop\n",
    "SLN_stats_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176849cd",
   "metadata": {},
   "source": [
    "Now we add a few more stats to the SLN_stats_out dataframe: mean Trophic position, normalized mean trophic position (by max trophic position), Trophic Omnivory (how many species eat at multiple trophic levels), and mean in-degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dce76d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the SLN\n",
    "sp_A_t = transpose(sp_A)\n",
    "G2=DiGraph(sp_A_t)\n",
    "nvertices = nv(G2) # number of vertices\n",
    "\n",
    "gplot(G2,layout=spring_layout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
