{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2378b349",
   "metadata": {},
   "source": [
    "## Rhynie Chert SLN Metrics Calculator ##\n",
    "### Adapted from \"Analytical approaches to networks, trophic structure, and ancient food webs\" NAPC 2024 food web workshop\n",
    "\n",
    "\n",
    "### Rhynie network ###\n",
    "The following script takes two types of files describing Species Level Networks (SLNs) as input. The first is a list of taxa and associated information like trophic guild assignment, habitat (terrestrial vs. aquatic), etc. The second file is the species-level adjacency matrix, which is a binary $\\vert U\\vert\\times \\vert U\\vert$ matrix, where $\\vert U\\vert$ is the total number of species in the network, $U$. The entries in this matrix are 0 or 1. If species $G_i$ preys on species $G_j$, then the $ij^{th}$ entry is 1, and zero otherwise.\n",
    "\n",
    "### Code note ###\n",
    "Note that much of the code and software written by Peter Roopnarine for working with metanetworks, constructing species-level food webs, calculating their metrics and simulating their dynamics, have been written using the Julia programming language. You must have Julia installed on your system to operate the code, and the Jupyter notebook environment installed for Julia. Helpful links are:\n",
    "\n",
    "https://julialang.org/\n",
    "\n",
    "https://jupyter.org/\n",
    "\n",
    "The following blocks of code are therefore all Julia. The code is licensed with the GNU General Protection License which, if you are not familiar with (but you should be!), allows users to freely reuse, modify and redistribute the original code. But please familiarize yourself with the obligations and restrictions of the license."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743f98cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nodes_in_loops"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load necessary Julia libraries\n",
    "# these must be installed via the Julia repl or terminal environment. Do so with the following commands\n",
    "# using Pkg\n",
    "# Pkg.add(\"CSV\")\n",
    "using CSV,DelimitedFiles,DataFrames,Random,Distributions,StatsPlots,LinearAlgebra,PoissonRandom,Graphs,Colors,FilePathsBase\n",
    "\n",
    "# also include custome functions that will be used to calculate particular metrics\n",
    "include(\"./loop_finder.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862ce77e",
   "metadata": {},
   "source": [
    "# Directory choice #\n",
    "Input which directory the SLN or SLNs you want to analyze are stored in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "704b907b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Messel\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# add the path from your working directory to the folder the SLN files are in\n",
    "## note that the matrix files should be named \"matrix_XXX.csv\" and the info files should be named \"speciesinfo_XXX.csv\"\n",
    "dir_path = \"SLNs/Messel\"\n",
    "# add a label for this analysis that will become the output table's filename\n",
    "analysis_name = \"Messel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b9e405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty dataframe to populate with metric values for each web\n",
    "SLN_stats_out = DataFrame(SLN_ID = String[], Detritus = Int64[], S = Float64[], interactions = Float64[], L_D = Float64[], C = Float64[],\n",
    "    Basal = Float64[], Top = Float64[], Herbiv_true = Float64[], Herbiv = Float64[], Carniv = Float64[],\n",
    "    meanInDegree = Float64[], stdInDegree = Float64[], \n",
    "    mean_NTP = Float64[], max_NTP = Float64[], mean_NTP_norm = Float64[], \n",
    "    TrOmniv = Float64[], q_inCoherence = Float64[], \n",
    "    diameter = Float64[], max_chain_len = Float64[],\n",
    "    mean_path_len = Float64[], std_path_len = Float64[],\n",
    "    loop = Float64[], Modularity = Float64[]\n",
    ")\n",
    "    \n",
    "# store the filenames of the matrix files from the specified directory \n",
    "matrix_files = sort(filter(f -> occursin(r\"matrix_.*\\.csv\", f), readdir(dir_path; join=true)))\n",
    "info_files = sort(filter(f -> occursin(r\"speciesinfo_.*\\.csv\", f), readdir(dir_path; join=true)))\n",
    "\n",
    "n_SLNs = length(matrix_files)\n",
    "\n",
    "#### the main loop begins below ####\n",
    "for index in 1:n_SLNs\n",
    "    ### File input ###\n",
    "    matrix_path = matrix_files[index]\n",
    "    # Extract the unique web ID (e.g., \"messel\", \"103\") from the matrix filename\n",
    "    ## Assumes filename format: \"matrix_WEBID.csv\"\n",
    "    web_id = match(r\"matrix_(.*)\\.csv\", basename(matrix_path)).captures[1]\n",
    "    # Find the corresponding species info file\n",
    "    ## We look for \"speciesinfo_WEBID.csv\" in the info_files list\n",
    "    expected_info_name = \"speciesinfo_$(web_id).csv\"\n",
    "    matching_info = filter(f -> basename(f) == expected_info_name, info_files)\n",
    "    if isempty(matching_info)\n",
    "        println(\"SKIPPING $web_id: Could not find $expected_info_name\")\n",
    "        continue\n",
    "    end\n",
    "    info_path = matching_info[1]\n",
    "    println(\"Processing $web_id...\")\n",
    "    println(\"   Matrix: \", basename(matrix_path))\n",
    "    println(\"   Info:   \", basename(info_path))\n",
    "\n",
    "    ## Read the species info and adjacency matrix files.\n",
    "    sp_P = CSV.read(info_path, DataFrame; \n",
    "        pool=false, \n",
    "        normalizenames=true, \n",
    "        ntasks=1,\n",
    "        stringtype=String\n",
    "        # quotechar='^' # Add these back if you haven't fixed the quotes in the files yet\n",
    "    )\n",
    "    sp_A_df = CSV.read(matrix_path, DataFrame; header = false)\n",
    "    sp_A = Matrix(sp_A_df)\n",
    "\n",
    "    if nrow(sp_P) != size(sp_A, 1)\n",
    "        error(\"DIMENSION MISMATCH for $web_id: Matrix has $(size(sp_A, 1)) rows, but Species Info has $(nrow(sp_P)) rows.\")\n",
    "    end\n",
    "\n",
    "    # FORCE CONVERT guild column to strings\n",
    "    sp_P.guild = string.(sp_P.guild)\n",
    "    \n",
    "    # pull the name/number of the network from the matrix filename\n",
    "    webname = match(r\"matrix_(.*)\\.csv\", matrix_files[index])\n",
    "    SLN_ID = webname !== nothing ? webname.captures[1] : missing\n",
    "     \n",
    "    #------------------------------------#\n",
    "    ### Basic stats ###\n",
    "\n",
    "    ## no. of interactions \n",
    "    interactions = sum(sp_A)\n",
    "    no_species = size(sp_A)[1]\n",
    "    ## link density\n",
    "    L_D = interactions/no_species\n",
    "    ## connectance\n",
    "    C = interactions/(no_species*(no_species-1))\n",
    "\n",
    "    #------------------------------------#\n",
    "    ### Check if no_preds and no_prey columns are missing/empty and fill in if so\n",
    "\n",
    "    # Make sure sp_no_prey and sp_no_preds columns are mutable and allow missing type\n",
    "    for colname in [:sp_no_prey, :sp_no_preds]\n",
    "        if !( colname in names(sp_P) )\n",
    "            sp_P[!, colname] = Vector{Union{Missing, Int}}(missing, nrow(sp_P))\n",
    "        elseif !(eltype(sp_P[!, colname]) <: Union{Missing, Int})\n",
    "            T = nonmissingtype(eltype(sp_P[!, colname]))\n",
    "            sp_P[!, colname] = Vector{Union{Missing, T}}(sp_P[!, colname])\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Fill in missing predator/prey counts\n",
    "    for i in 1:no_species\n",
    "        if ismissing(sp_P.sp_no_prey[i])\n",
    "            sp_P.sp_no_prey[i] = sum(sp_A[i, :])  # Row = outgoing links (prey)\n",
    "        end\n",
    "        if ismissing(sp_P.sp_no_preds[i])\n",
    "            sp_P.sp_no_preds[i] = sum(sp_A[:, i])  # Col = incoming links (predators)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    #------------------------------------#\n",
    "    ### Trophic Composition ###\n",
    "\n",
    "    ## Basal: fraction of total species (minus detritus) that eat only basal species\n",
    "\n",
    "    # Identify basal species (no incoming links)\n",
    "    is_basal = [sum(sp_A[i, j] for j in 1:no_species) == 0 for i in 1:no_species]\n",
    "    # Identify how many of the taxa are detritus and reports how many detrital nodes are reported in the web\n",
    "    detritalnodes = findall(occursin.(\"detritus\", sp_P.guild))\n",
    "    Detritus = length(detritalnodes)\n",
    "\n",
    "    Basal = (sum(is_basal)-length(detritalnodes))/(no_species-length(detritalnodes))\n",
    "\n",
    "    ## Top: fraction of total species (minus detritus) with no predators\n",
    "    is_top = [sum(sp_A'[i, j] for j in 1:no_species) == 0 for i in 1:no_species]\n",
    "\n",
    "    Top = sum(is_top)/no_species\n",
    "\n",
    "    ## Herbivores, Carnivores: fraction of consumer species that eat only basal species, only non-basal species\n",
    "\n",
    "    herbivores = 0\n",
    "    carnivores = 0\n",
    "    consumers = 0\n",
    "\n",
    "    ## herbivores_true: consumers that eat only basal species that are not detritus\n",
    "    herbivores_true = 0\n",
    "\n",
    "    for i in 1:no_species\n",
    "        prey = findall(sp_A[i, :] .== 1)\n",
    "        if !isempty(prey)\n",
    "            consumers += 1\n",
    "            if all(is_basal[j] for j in prey)\n",
    "                herbivores += 1\n",
    "                # \"For all items 'p' in 'prey', check that 'p' is NOT in 'detritalnodes'\"\n",
    "                if all(p -> !(p in detritalnodes), prey) \n",
    "                    herbivores_true +=1\n",
    "                end\n",
    "            end\n",
    "            if all(!is_basal[j] for j in prey)\n",
    "                carnivores += 1\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    Herbiv = herbivores/consumers\n",
    "    Carniv = carnivores/consumers\n",
    "    \n",
    "    Herbiv_true = herbivores_true/consumers\n",
    "    #------------------------------------#\n",
    "    ## Mean and st. dev. in-degree (generality), mean # of prey species\n",
    "\n",
    "    meanInDegree = sum(sp_P.sp_no_prey)/consumers\n",
    "    stdInDegree = std(sp_P.sp_no_prey[sp_P.sp_no_prey .!= 0])\n",
    "\n",
    "    #------------------------------------#\n",
    "    ### Chain length/NTP analyses ###\n",
    "\n",
    "    # store number of guilds for later use\n",
    "    # no_guilds = maximum(sp_P.guild_no)\n",
    "    # add columns to the species dataframe to store the longest chain and ntp\n",
    "    sp_P[!, :sp_ntp] = fill(0.0, nrow(sp_P))\n",
    "    sp_P[!, :sp_long_chain] = fill(0.0, nrow(sp_P))\n",
    "\n",
    "    #initialize pathways matrix\n",
    "    paths = Array{Int64}(undef,no_species,no_species)\n",
    "    paths = deepcopy(sp_A)\n",
    "    #longest possible pathway. for rhynie this is the number of guilds, but here is generalized for networks not drawn from a guild metaweb\n",
    "    P_max = min(no_species - 1, 30) # max of 30 to avoid computational overload in large food webs\n",
    "    #set initial longest path for each species\n",
    "    for i = 1:no_species\n",
    "        if sp_P[i,:sp_no_prey] > 0\n",
    "            sp_P[i,:sp_long_chain] = 1\n",
    "        end\n",
    "    end\n",
    "        \n",
    "    #calculate pathways by raising binary adjacency matrix to pathway lengths\n",
    "    for i = 1:P_max\n",
    "        A2 = sp_A^i\n",
    "        for j = 1:no_species\n",
    "            for k = 1:no_species\n",
    "                #if path now exists between species\n",
    "                if paths[j,k]==0 && A2[j,k]>0\n",
    "                    #update the pathways matrix\n",
    "                    paths[j,k] = i\n",
    "                end\n",
    "            end\n",
    "            #list as longest chain if one exists\n",
    "            if sum(paths[j,:]) != 0\n",
    "                sp_P[j,:sp_long_chain] = maximum(paths[j,:])\n",
    "            end\n",
    "        end       \n",
    "        if sum(A2)==0\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    ## Closeness Centrality    \n",
    "    ### OUTBOUND closeness (how accessible resources are to consumers) -- probably more useful\n",
    "    ## new column in sp_P to record Outbound closeness centrality\n",
    "    sp_P[!, :sp_out_closeness] = fill(0.0, nrow(sp_P))\n",
    "\n",
    "    for i in 1:no_species\n",
    "        # Extract distances from species 'i' to everyone else\n",
    "        dists = paths[:, i]\n",
    "        \n",
    "        # filter valid interactions\n",
    "        # only sum paths that are > 0 (reachable) AND not to itself (index != i)\n",
    "        valid_paths = [dists[k] for k in 1:no_species if dists[k] > 0 && k != i]\n",
    "        \n",
    "        # Sum the shortest pathways\n",
    "        sum_paths = sum(valid_paths)\n",
    "        \n",
    "        # Apply the formula: (N-1) / Sum\n",
    "        # We check if sum_paths > 0 to avoid dividing by zero (for species with no prey)\n",
    "        if sum_paths > 0\n",
    "            sp_P.sp_out_closeness[i] = (no_species - 1) / sum_paths\n",
    "        else\n",
    "            sp_P.sp_out_closeness[i] = 0.0\n",
    "        end\n",
    "    end\n",
    "    ### INBOUND closeness (how connected consumers are to resources)\n",
    "    ## new column in sp_P to record Inbound closeness centrality\n",
    "    sp_P[!, :sp_in_closeness] = fill(0.0, nrow(sp_P))\n",
    "\n",
    "    for i in 1:no_species\n",
    "        # Extract distances to species 'i' from everyone else\n",
    "        dists = paths[i, :]\n",
    "        \n",
    "        # filter valid interactions\n",
    "        # only sum paths that are > 0 (reachable) AND not to itself (index != i)\n",
    "        valid_paths = [dists[k] for k in 1:no_species if dists[k] > 0 && k != i]\n",
    "        \n",
    "        # Sum the shortest pathways\n",
    "        sum_paths = sum(valid_paths)\n",
    "        \n",
    "        # Apply the formula: (N-1) / Sum\n",
    "        # We check if sum_paths > 0 to avoid dividing by zero (for species with no prey)\n",
    "        if sum_paths > 0\n",
    "            sp_P.sp_in_closeness[i] = (no_species - 1) / sum_paths\n",
    "        else\n",
    "            sp_P.sp_in_closeness[i] = 0.0\n",
    "        end\n",
    "    end\n",
    "\n",
    "    #calculate ntps\n",
    "    #build vector of primary producers\n",
    "    prods = Int64[]\n",
    "    for i = 1:no_species\n",
    "        if sp_P[i,:sp_no_prey] == 0\n",
    "            push!(prods,i)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    #calculate path length of prey to producers\n",
    "    for i = 1:no_species\n",
    "        if sp_P[i,:sp_no_prey]==0 #if producer\n",
    "            sp_P[i,:sp_ntp] = 1\n",
    "            elseif sp_P[i,:sp_no_prey]>0 #else if consumer\n",
    "                #list prey\n",
    "                its_prey = Int64[]\n",
    "                path_length = 0\n",
    "                no_paths = 0\n",
    "                for j = 1:no_species\n",
    "                    #if species is producer prey of i\n",
    "                    if paths[i,j] == 1 && sp_P[j,:sp_no_prey] == 0\n",
    "                        no_paths+=1\n",
    "                    end\n",
    "                    #if species is consumer prey of i\n",
    "                    if paths[i,j] == 1 && sp_P[j,:sp_no_prey] > 0\n",
    "                        #record path lengths to producers\n",
    "                        for k = 1:no_species\n",
    "                            if paths[j,k]!=0 && sp_P[k,:sp_no_prey]==0\n",
    "                                path_length = path_length + paths[j,k]\n",
    "                                no_paths+=1\n",
    "                            end\n",
    "                        end\n",
    "                    end \n",
    "                end\n",
    "                #if herbivore\n",
    "                if path_length==0\n",
    "                    sp_P[i,:sp_ntp] = 2.0\n",
    "                elseif path_length > 0\n",
    "                    #if not herbivore\n",
    "                    sp_P[i,:sp_ntp] = 2.0 + (Float64(path_length)/Float64(no_paths))\n",
    "                    #println(species[i,6])\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "\n",
    "    ## mean net trophic position (ntp)\n",
    "    mean_NTP = mean(sp_P.sp_ntp)\n",
    "\n",
    "    ## max and normalized mean ntp (divide by max value of ntp)\n",
    "    max_NTP = maximum(sp_P.sp_ntp)\n",
    "    mean_NTP_norm = mean_NTP / max_NTP\n",
    "\n",
    "    ## Trophic Omnivory: fraction of consumer species that eat across trophic levels\n",
    "    num_integers = count(x -> isfinite(x) && x % 1 == 0, sp_P.sp_ntp)\n",
    "    trophic_omnivores = no_species - num_integers\n",
    "    TrOmniv = trophic_omnivores/consumers\n",
    "\n",
    "    #------------------------------------#\n",
    "    ## Trophic Coherence ###\n",
    "\n",
    "    ## incoherence (q) is a metric from Johnson et al. 2014 and is related to TrophOmniv\n",
    "    ## it is the standard deviation of differences between ntps of predator and prey across for all links in the web\n",
    "\n",
    "    # make a list of all edges (trophic links) in the SLN\n",
    "    graph = DiGraph(sp_A)\n",
    "    links = collect(edges(graph))\n",
    "\n",
    "    # create an empty vector to store ntp differences for all edges \n",
    "    troph_distances = Float64[]\n",
    "\n",
    "    # Loop through all edges and calculate ntp differences\n",
    "    # note that the direction of source and destination seems backwards from an energy POV-->in graphs the standard direction is from the predator to the prey\n",
    "    for e in edges(graph)\n",
    "        i = src(e) # consumer sp ID\n",
    "        j = dst(e) # resource sp ID\n",
    "        ntp_i = sp_P[i, :sp_ntp]\n",
    "        ntp_j = sp_P[j, :sp_ntp]\n",
    "        push!(troph_distances, ntp_i - ntp_j)\n",
    "    end\n",
    "\n",
    "    # compute standard deviation\n",
    "    q_inCoherence = std(troph_distances)\n",
    "\n",
    "    #------------------------------------#\n",
    "    ### Diameter ####\n",
    "\n",
    "    # Compute all-pairs shortest paths\n",
    "    all_paths = floyd_warshall_shortest_paths(SimpleDiGraph(sp_A))\n",
    "\n",
    "    # Extract all finite path lengths\n",
    "    lengths = Float64[]\n",
    "    for i in 1:no_species\n",
    "        for j in 1:no_species\n",
    "            d = all_paths.dists[i, j]\n",
    "            if i != j && (d) < 100000\n",
    "                push!(lengths, d)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    diameter = maximum(lengths)\n",
    "    mean_path_len = mean(lengths)\n",
    "    std_path_len = std(lengths)\n",
    "    #------------------------------------#\n",
    "    ### Max chain length\n",
    "\n",
    "   # 1. Define a recursive function to find depth\n",
    "    #    'current_node': The species we are looking at\n",
    "    #    'visited': A list of species already in this specific food chain\n",
    "\n",
    "    function get_max_chain_depth(node_id, matrix, visited, start_time, time_limit)\n",
    "        \n",
    "        # Find all prey for this node (Where matrix row has 1s)\n",
    "        prey_list = findall(matrix[node_id, :] .== 1)\n",
    "        \n",
    "        # If no prey, this is the end of the line (Basal)\n",
    "        if isempty(prey_list)\n",
    "            return 1.0\n",
    "        end\n",
    "        \n",
    "        max_prey_depth = 0.0\n",
    "        \n",
    "        for prey in prey_list\n",
    "            # --- TIME CHECK ---\n",
    "            # Check time inside the loop. \n",
    "            # If time runs out, we BREAK the loop but keep our current 'max_prey_depth'.\n",
    "            if (time() - start_time) > time_limit\n",
    "                break \n",
    "            end\n",
    "            # ---------------------------\n",
    "\n",
    "            # Only proceed if we haven't eaten this species in this chain yet\n",
    "            if !(prey in visited)\n",
    "                \n",
    "                # Add prey to visited list for the next step\n",
    "                push!(visited, prey)\n",
    "                \n",
    "                # Go deeper\n",
    "                depth = get_max_chain_depth(prey, matrix, visited, start_time, time_limit)\n",
    "                \n",
    "                # Keep the largest depth found\n",
    "                if depth > max_prey_depth\n",
    "                    max_prey_depth = depth\n",
    "                end\n",
    "                \n",
    "                # Backtrack: Remove prey from visited so other paths can use it\n",
    "                delete!(visited, prey)\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        # My depth is 1 (me) + the deepest path below me\n",
    "        return 1.0 + max_prey_depth\n",
    "    end\n",
    "\n",
    "    #  Run the following for every species in this web\n",
    "    #    (We re-initialize the 'visited' set for each species)\n",
    "    trophic_height = zeros(Float64, no_species)\n",
    "\n",
    "    for i in 1:no_species\n",
    "        # Capture the start time for this specific search\n",
    "        t0 = time()\n",
    "        # Set a time limit for each species search, in seconds\n",
    "        maxtime = 10\n",
    "        # Start the search with just the current species in the visited set\n",
    "        trophic_height[i] = get_max_chain_depth(i, sp_A, Set([i]), t0, maxtime)\n",
    "\n",
    "        # Print a warning if it actually timed out\n",
    "        if (time() - t0) > maxtime\n",
    "            println(\"  Warning: Search for species $i in $SLN_ID timed out. Result may be underestimated.\")\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Calculate the metric\n",
    "    max_chain_len = maximum(trophic_height)\n",
    "\n",
    "    #------------------------------------#\n",
    "    ### Loop ###\n",
    "    \n",
    "    # use custom function to return boolean list of species involved in trophic cycles\n",
    "    spp_in_loops = nodes_in_loops(sp_A)\n",
    "\n",
    "    # loop is the fraction of all species involved in non-cannibalistic cycles (e.g., Dunne et al. 2008)\n",
    "    loop = sum(spp_in_loops)/no_species\n",
    "    #------------------------------------#\n",
    "    ### Guild-level metrics (ntp and closeness centralities) ###\n",
    "    \n",
    "    # create new columns filled with 0.0 (Float64)\n",
    "    sp_P[!, :guild_ntp] = fill(0.0, nrow(sp_P))\n",
    "    sp_P[!, :guild_out_closeness] = fill(0.0, nrow(sp_P))\n",
    "    sp_P[!, :guild_in_closeness] = fill(0.0, nrow(sp_P))\n",
    "\n",
    "    # get list of unique guilds\n",
    "    guild_names = unique(sp_P.guild)\n",
    "\n",
    "    for g in guild_names\n",
    "        logical_mask = sp_P.guild .== g\n",
    "\n",
    "        ntp_mean = mean(sp_P.sp_ntp[logical_mask])\n",
    "        sp_P.guild_ntp[logical_mask] .= ntp_mean\n",
    "\n",
    "        out_closeness_mean = mean(sp_P.sp_out_closeness[logical_mask])\n",
    "        sp_P.guild_out_closeness[logical_mask] .= out_closeness_mean\n",
    "        \n",
    "        in_closeness_mean = mean(sp_P.sp_in_closeness[logical_mask])\n",
    "        sp_P.guild_in_closeness[logical_mask] .= in_closeness_mean\n",
    "\n",
    "    end\n",
    "    \n",
    "    #------------------------------------#\n",
    "    ### Modularity ###\n",
    "\n",
    "\n",
    "    \n",
    "    #------------------------------------#\n",
    "    #### Metrics Output ####\n",
    "\n",
    "    # save updated speciesinfo with path length and ntp info\n",
    "    CSV.write(info_files[index], sp_P)\n",
    "\n",
    "    # push metrics to SLN_stats_out\n",
    "    push!(SLN_stats_out, (SLN_ID, Detritus, no_species, interactions, L_D, C, \n",
    "        Basal, Top, Herbiv_true, Herbiv, Carniv,\n",
    "        meanInDegree, stdInDegree, mean_NTP, max_NTP, mean_NTP_norm,\n",
    "        TrOmniv, q_inCoherence, diameter, max_chain_len,\n",
    "        mean_path_len, std_path_len, loop, 0    \n",
    "    ))  # Order must match column order\n",
    "    println(\"Updated species info file #$(webname[1]) and pushed metrics to dataframe.\")\n",
    "end\n",
    "\n",
    "# save SLN_stats_out as a csv\n",
    "CSV.write(joinpath(dir_path, \"WebMetrics_$analysis_name.csv\"), SLN_stats_out)\n",
    "println(\"Successfully completed metrics calculations for $analysis_name and outputted table as .csv.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
